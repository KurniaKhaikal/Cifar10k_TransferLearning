{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature2_Cifar10.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KurniaKhaikal/Cifar10k_TransferLearning/blob/main/Feature2_Cifar10_VGG19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mgc9DQdUD4FM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "import random\n",
        "import matplotlib.pylab as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "api_token = {\"username\":\"khaikal\",\"key\":\"9e492a7553b8e713debda6f4f6810151\"}\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Ri3pujnYEHx3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d oxcdcd/cifar10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ1f4xcHEJo2",
        "outputId": "3941e0b4-d320-4e15-a352-28bfed305952"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading cifar10.zip to /content\n",
            " 99% 174M/175M [00:01<00:00, 161MB/s]\n",
            "100% 175M/175M [00:01<00:00, 175MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/content/cifar10.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "Ri0aNXUrEOsn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"/content/cifar10/Base2\""
      ],
      "metadata": {
        "id": "G1RjViFWO610"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dataset = \"/content/cifar10/Base2\""
      ],
      "metadata": {
        "id": "o6cGaKnIEb1n"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_dir = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "IMAGE_SIZE = (224, 224)"
      ],
      "metadata": {
        "id": "0IzLkStZEk6c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pii9O37sMUvH",
        "outputId": "be25d0f9-88f6-4a41-8e4e-9798ebe9c3d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "\n",
        "\n",
        "splitfolders.ratio(\"/content/cifar10/test\", output=\"/content/cifar10/Base2\",\n",
        "    seed=1337, ratio=(.9, .1), group_prefix=None, move=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boRDVEYEMgXf",
        "outputId": "571961bc-ce82-425b-b979-6fc6978bd4f2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 10000 files [00:01, 7060.30 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# indexing file images\n",
        "dataset_train = []\n",
        "for class_item in class_dir:\n",
        "    cur_dir = os.path.join(base_dataset, 'train', class_item)\n",
        "    for file in os.listdir(cur_dir):\n",
        "        dataset_train.append(os.path.join(cur_dir, file))"
      ],
      "metadata": {
        "id": "F2HNxKtaEpEm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train:\", len(dataset_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saWkAJUjEr9E",
        "outputId": "43e98633-b55a-4022-fc76-1f717a8f2c5d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imutils import paths\n",
        "import cv2\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "metadata": {
        "id": "2Ndn1hDwEt4t"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] load images Cifar10k dataset...\")\n",
        "#  load images\n",
        "train_images = []\n",
        "for image_path in dataset_train:\n",
        "    if \".jpg\" or \".jpeg\" in image_path:\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image, IMAGE_SIZE)\n",
        "        train_images.append(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBtczzriEvps",
        "outputId": "68599ec4-3c24-4004-8b10-1748b8ac6e74"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] load images Cifar10k dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# normalization\n",
        "print(\"[INFO] normalization...\")\n",
        "train_x = np.array(train_images).astype(\"float32\") / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy4pubPFE1dX",
        "outputId": "6ebdc09d-6056-47f7-a9a9-328e6c9e8def"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] normalization...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "P9TJKiohNWsP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "modelVGG19 = VGG19(weights=\"imagenet\")\n",
        "model = Model(inputs=modelVGG19.input, outputs=modelVGG19.get_layer(\"fc1\").output)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkkIAwKLNPBv",
        "outputId": "106f7ad0-7ce7-4f00-a91d-827a68a61043"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
            "574717952/574710816 [==============================] - 5s 0us/step\n",
            "574726144/574710816 [==============================] - 5s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 122,788,928\n",
            "Trainable params: 122,788,928\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = model.predict(train_x)"
      ],
      "metadata": {
        "id": "tV5jpmG0NlBn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexes = list(range(0, train_x.shape[0]))\n",
        "features_array = [[float(x) for x in y] for y in features]\n",
        "labels = [path.split(\"/\")[5] for path in dataset_train]\n",
        "data_train = {\"indexes\": indexes, \"features\": features_array, \"locations\": dataset_train, \"labels\":labels}"
      ],
      "metadata": {
        "id": "o3bur51-gwCf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/feature_extraction.json', 'w') as f:\n",
        "    json.dump(data_train, f)"
      ],
      "metadata": {
        "id": "N9sJn6rPg6w_"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}