{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransferLearning_Cifar10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNzDMEx8hlqT1b+A/IDzspa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KurniaKhaikal/Cifar10k_TransferLearning/blob/main/TransferLearning_Cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W-a1SvaLkOdt"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import sklearn.metrics as metric\n",
        "from tensorflow.keras.models import Model\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZTaOK2qk5fv",
        "outputId": "095fddbe-233d-40ba-e84f-3e6cd15b6d7d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "api_token = {\"username\":\"khaikal\",\"key\":\"9e492a7553b8e713debda6f4f6810151\"}\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Jy8I3OgulGE2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d oxcdcd/cifar10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpDKYqNxlIbe",
        "outputId": "c3a9fb4f-66c0-4af9-a460-d1787c0036fe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading cifar10.zip to /content\n",
            "100% 175M/175M [00:01<00:00, 153MB/s]\n",
            "100% 175M/175M [00:01<00:00, 161MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/content/cifar10.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "MEdLp0_llK52"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB_tqYWMltpm",
        "outputId": "6d6af2ef-f5de-413a-f4a9-9087c34c52ba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "\n",
        "\n",
        "splitfolders.ratio(\"/content/cifar10/test\", output=\"/content/drive/MyDrive/Proposal2/Cifar10/Cifar_dataset/cifar10/Base2\",\n",
        "    seed=1337, ratio=(.9, .1), group_prefix=None, move=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPPPq5wslcG2",
        "outputId": "0dfa30f2-3213-4cdc-f08b-de116cb3d40b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 10000 files [01:49, 91.09 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean(a, b):\n",
        "\treturn np.linalg.norm(a - b)"
      ],
      "metadata": {
        "id": "PBzTWsTLmPs2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_search(query_features, indexed_train, max_results=5):\n",
        "\tretrieved = []\n",
        "\tfor idx in range(0, len(indexed_train[\"features\"])):\n",
        "\t\tdistance = euclidean(query_features, indexed_train[\"features\"][idx])\n",
        "\t\tretrieved.append((distance, idx))\n",
        "\tretrieved = sorted(retrieved)[:max_results]\n",
        "\treturn retrieved"
      ],
      "metadata": {
        "id": "21PRrNSJmUlm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dataset = \"/content/drive/MyDrive/Proposal2/Cifar10/Cifar_dataset/cifar10/Base2\"\n",
        "class_dir = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
        "IMAGE_SIZE = (224, 224)"
      ],
      "metadata": {
        "id": "eOZv2wmhmWK-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# indexing file images\n",
        "dataset_test = []\n",
        "for class_item in class_dir:\n",
        "    cur_dir = os.path.join(base_dataset, 'val', class_item)\n",
        "    for file in os.listdir(cur_dir):\n",
        "        dataset_test.append(os.path.join(cur_dir, file))"
      ],
      "metadata": {
        "id": "-UAg7m1FmmZf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"len to retrieving:\", len(dataset_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImieKG9vmr-I",
        "outputId": "70ffc15f-8dd3-46ae-d777-b97d8039def1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len to retrieving: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] load images Corel-Image 1k dataset...\")\n",
        "#  load images\n",
        "val_images = []\n",
        "for image_path in dataset_test:\n",
        "    if \".jpg\" or \".jpeg\" in image_path:\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image, IMAGE_SIZE)\n",
        "        val_images.append(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8VOzFZgmthP",
        "outputId": "0e477e05-87e9-4baa-fe5f-cc6908222e72"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] load images Corel-Image 1k dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] normalization...\")\n",
        "val_x = np.array(val_images).astype(\"float32\") / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rt41kcAm1Ue",
        "outputId": "af5b7d8f-81ab-4f7c-e224-0ff3aec25e6a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] normalization...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "modelVGG16 = VGG16(weights=\"imagenet\")\n",
        "model = Model(inputs=modelVGG16.input, outputs=modelVGG16.get_layer(\"fc1\").output)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoSPuK_um6ce",
        "outputId": "ba86ca90-ce0d-4e25-dd76-ccc64d53265b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 117,479,232\n",
            "Trainable params: 117,479,232\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = model.predict(val_x)"
      ],
      "metadata": {
        "id": "3JHP2D75m_9m"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Proposal2/Cifar10/Cifar_dataset/cifar10/Base2/feature_extraction.json') as f:\n",
        "  training_indexed = json.load(f)"
      ],
      "metadata": {
        "id": "7BwxDoEOnHYW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_indexes = list(range(0, val_x.shape[0]))\n",
        "label_builder = list(np.unique(training_indexed[\"labels\"]))\n",
        "class_builder = {label_unique:[] for label_unique in label_builder}\n",
        "recalls = copy.deepcopy(class_builder)\n",
        "precisions = copy.deepcopy(class_builder)\n",
        "# loop over the testing indexes\n",
        "for i in query_indexes:\n",
        "    queryFeatures = features[i]\n",
        "    results = perform_search(queryFeatures, training_indexed, max_results=5)\n",
        "    labels_ret = [training_indexed[\"labels\"][r[1]] for r in results]\n",
        "    label_true = dataset_test[i].split(\"/\")[8]\n",
        "    label_trues = [label_true for _ in labels_ret]\n",
        "    recall = metric.recall_score(label_trues, labels_ret, average='weighted')\n",
        "    precision = metric.precision_score(label_trues, labels_ret, average='weighted')\n",
        "    recalls[label_true].append(recall)\n",
        "    precisions[label_true].append(precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "HjXAwgjWthrm",
        "outputId": "f3154a67-8054-43c6-e90a-6f1e3574ddab"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-7dd8867c44d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery_indexes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mqueryFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperform_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueryFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_indexed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mlabels_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtraining_indexed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlabel_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-c374677a8fa7>\u001b[0m in \u001b[0;36mperform_search\u001b[0;34m(query_features, indexed_train, max_results)\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mretrieved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                 \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meuclidean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexed_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                 \u001b[0mretrieved\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mretrieved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieved\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-a61c19e36827>\u001b[0m in \u001b[0;36meuclidean\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meuclidean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"recall values:\")\n",
        "comb_recall, comb_precision = [], []\n",
        "for key in recalls.keys():\n",
        "    average_val = np.average(recalls[key])\n",
        "    print(key, average_val)\n",
        "    comb_recall.append(average_val)\n",
        "print(\"combined recall\", np.average(comb_recall))\n",
        "\n",
        "print(\"\\nprecision values:\")\n",
        "for key in precisions.keys():\n",
        "    average_val = np.average(precisions[key])\n",
        "    print(key, average_val)\n",
        "    comb_precision.append(average_val)\n",
        "print(\"combined precision\", np.average(comb_precision))"
      ],
      "metadata": {
        "id": "QHPjQ59qvwgO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}